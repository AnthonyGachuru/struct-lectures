@Article{Todd2006,
  Title                    = {Assessing the Impact of a School Subsidy Program in Mexico: Using a Social Experiment to Validate a Dynamic Behavioral Model of Child Schooling and Fertility},
  Author                   = {Todd, Petra E. and Wolpin, Kenneth I.},
  Journal                  = {American Economic Review},
  Year                     = {2006},

  Month                    = {December},
  Number                   = {5},
  Pages                    = {1384-1417},
  Volume                   = {96},

  Doi                      = {10.1257/aer.96.5.1384},
  File                     = {:inbox/todd_wolpin_progresa.pdf:PDF},
  Url                      = {http://www.aeaweb.org/articles?id=10.1257/aer.96.5.1384}
}


@TechReport{NRC2012,
  Title                    = {Assessing the Reliability of Complex Models:
 Mathematical and Statistical Foundations of
 Verification, Validation, and Uncertainty
 Quantification},
  Author                   = {{National Research Council}},
  Institution              = {NRC},
  Year                     = {2012},

  Address                  = {Washington, D.C.},

  Abstract                 = {Advances in computing hardware and algorithms have dramatically improved the ability to simulate complex processes computationally. Today's simulation capabilities offer the prospect of addressing questions that in the past could be addressed only by resource-intensive experimentation, if at all. Assessing the Reliability of Complex Models recognizes the ubiquity of uncertainty in computational estimates of reality and the necessity for its quantification.

As computational science and engineering have matured, the process of quantifying or bounding uncertainties in a computational estimate of a physical quality of interest has evolved into a small set of interdependent tasks: verification, validation, and uncertainty of quantification (VVUQ). In recognition of the increasing importance of computational simulation and the increasing need to assess uncertainties in computational results, the National Research Council was asked to study the mathematical foundations of VVUQ and to recommend steps that will ultimately lead to improved processes.

Assessing the Reliability of Complex Models discusses changes in education of professionals and dissemination of information that should enhance the ability of future VVUQ practitioners to improve and properly apply VVUQ methodologies to difficult problems, enhance the ability of VVUQ customers to understand VVUQ results and use them to make informed decisions, and enhance the ability of all VVUQ stakeholders to communicate with each other. This report is an essential resource for all decision and policy makers in the field, students, stakeholders, UQ experts, and VVUQ educators and practitioners.},
  File                     = {:inbox/reliability_of_complex_models.pdf:PDF},
  Owner                    = {janos},
  Publisher                = {The National Academies Press},
  Timestamp                = {2017.12.13}
}


@Book{Lumsdaine1990,
  Title                    = {Three Models of Retirement: Computational Complexity Versus Predictive Validity},
  Author                   = {Lumsdaine, R.L. and Stock, J.H. and Wise, D.A. and National Bureau of Economic Research},
  Publisher                = {National Bureau of Economic Research},
  Year                     = {1990},
  Number                   = {Nr. 3558},
  Series                   = {NBER working paper},

  File                     = {:inbox/three_models_of_retirement.pdf:PDF},
  Url                      = {https://books.google.de/books?id=WqsiAQAAMAAJ}
}


@Unpublished{DellaVigna2017a,
  Title                    = {Structural Behavioral Economics},
  Author                   = {DellaVigna, Stefano},
  Note                     = {Future Handbook Chapter},

  Month                    = {November},
  Year                     = {2017},

  File                     = {:inbox/DellaVigna.2018.pdf:PDF},
  Owner                    = {janos},
  Timestamp                = {2018.1.27}
}



@Article{Rust2014,
  Title                    = {The Limits of Inference with Theory: A Review of Wolpin (2013)},
  Author                   = {Rust, John},
  Journal                  = {Journal of Economic Literature},
  Year                     = {2014},

  Month                    = {September},
  Number                   = {3},
  Pages                    = {820-50},
  Volume                   = {52},

  Abstract                 = {This essay reviews Kenneth I. Wolpin's (2013) monograph The Limits of Inference without Theory, which arose from lectures he presented at the Cowles Foundation in 2010 in honor of Tjalling Koopmans. While I readily agree with Wolpin's basic premise that empirical work that eschews the role of economic theory faces unnecessary self-imposed limits relative to empirical work that embraces and tries to test and improve economic theory, it is important to be aware that the use of economic theory is not a panacea. I point out that there are also serious limits to inference with theory: 1) there may be no truly "structural" (policy invariant) parameters, a key assumption underpinning the structural econometric approach that Wolpin and the Cowles Foundation have championed; 2) there is a curse of dimensionality that makes it very difficult for us to elucidate the detailed implications of economic theories, which is necessary to empirically implement and test these theories; 3) there is an identification problem that makes it impossible to decide between competing theories without imposing ad hoc auxiliary assumptions (such as parametric functional form assumptions); and 4) there is a problem of multiplicity and indeterminacy of equilibria that limits the predictive empirical content of many economic theories. I conclude that though these are very challenging problems, I agree with Wolpin and the Cowles Foundation that economists have far more to gain by trying to incorporate economic theory into empirical work and test and improve our theories than by rejecting theory and presuming that all interesting economic issues can be answered by well-designed controlled, randomized experiments and assuming that difficult questions of causality and evaluation of alternative hypothetical policies can be resolved by simply allowing the "data to speak for itself."},
  Doi                      = {10.1257/jel.52.3.820},
  File                     = {:inbox/limits_with_theory.pdf:PDF},
  Url                      = {http://www.aeaweb.org/articles?id=10.1257/jel.52.3.820}
}


@Book{Wolpin2013,
  Title                    = {The Limits of Inference without Theory},
  Author                   = {Kenneth I. Wolpin},
  Publisher                = {MIT Press},
  Year                     = {2013},

  Abstract                 = {<p>In this rigorous and well-crafted work, Kenneth Wolpin examines the role of theory in inferential empirical work in economics and the social sciences in general -- that is, any research that uses raw data to go beyond the mere statement of fact or the tabulation of statistics. He considers in particular the limits that eschewing the use of theory places on inference. Wolpin finds that the absence of theory in inferential work that addresses microeconomic issues is pervasive. That theory is unnecessary for inference is exemplified by the expression "let the data speak for themselves." This approach is often called "reduced form." A more nuanced view is based on the use of experiments or quasi-experiments to draw inferences. Atheoretical approaches stand in contrast to what is known as the structuralist approach, which requires that a researcher specify an explicit model of economic behavior -- that is, a theory. Wolpin offers a rigorous examination of both structuralist and nonstructuralist approaches. He first considers ex ante policy evaluation, highlighting the role of theory in the implementation of parametric and nonparametric estimation strategies. He illustrates these strategies with two examples, a wage tax and a school attendance subsidy, and summarizes the results from applications. He then presents a number of examples that illustrate the limits of inference without theory: the effect of unemployment benefits on unemployment duration; the effect of public welfare on women's labor market and demographic outcomes; the effect of school attainment on earnings; and a famous field experiment in education dealing with class size. Placing each example within the context of the broader literature, he contrasts them to recent work that relies on theory for inference.</p>},
  ISBN                     = {9780262019088},
  Owner                    = {janos},
  Timestamp                = {2018.01.29},
  Url                      = {http://www.jstor.org/stable/j.ctt5vjpxr}
}

